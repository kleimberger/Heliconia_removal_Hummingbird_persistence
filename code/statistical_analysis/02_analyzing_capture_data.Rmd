---
title: "Analyzing capture data"
output: html_document
knit: (function(inputFile, encoding) {
      out_dir <- "knitted_markdown_files";
      rmarkdown::render(inputFile,
                        encoding=encoding,
                        output_dir=file.path(dirname(inputFile), out_dir))})
---

**Goals**

Analyze how experimental *Heliconia* removal influences:

- Number of hummingbirds captured
- Hummingbird recapture rate (number of birds tagged 'pre' that were recaptured 'post')

```{r setup, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

#Packages for statistical modeling
library(glmmTMB)
library(AICcmodavg)
library(DHARMa)
library(emmeans)
library(ggeffects)

#Packages for data wrangling
library(dplyr)
library(tidyr)
library(lubridate)
library(purrr)

#Packages for plotting
library(ggplot2)
library(ggrepel)
library(ggpubr)

#Set up parallel processing (likelihood profile CI take forever to run!)
library(future)
plan(multisession)

#Set seed
set.seed(1)
```

## Step 1: Import data and functions

**Data for analysis**
```{r}
#Capture data. Number of birds captured per capture session, with capture effort
capture_data <- read.csv("data/export/for_analysis/Capture_rates.csv") %>%
  mutate(subanalysis = "captures") %>%
  select(-X, -date)

head(capture_data)

#Recapture data
#1. Remove patches without data (no birds caught during pre)
#2. Remove patch without constant capture effort pre & post. So can avoid including covariates for effort
recapture_data <- read.csv("data/export/for_analysis/Recapture_rates.csv") %>%
  mutate(subanalysis = "recaptures") %>%
  filter(!is.na(recap_rate)) %>%  
  filter(!(patch == "203" & year == "2017")) %>%
  select(-X)

head(recapture_data)

#Resource data. Need to add quantitative treatment measure here (*Heliconia* calories removed/ha)
heto_removed <- read.csv("data/export/for_analysis/Heliconia_resources_removed_as_treatment.csv") %>%
  select(-X, -area)

##1. Combine data
#2. Log-transform HETO calories removed
#3. Remove plants without flower counts (GINGY and MARA-VER)
capture_data_for_analysis <- capture_data %>%
  bind_rows(recapture_data) %>%
  left_join(heto_removed) %>%
  mutate(exp_phase = factor(exp_phase, levels = c("capture_1", "capture_2"), labels = c("pre", "post"))) %>%
  mutate(control_treatment = factor(control_treatment, levels = c("control", "treatment"))) %>%
  mutate(year_patch = paste(year, patch, sep = "_")) %>%
  mutate(log_calories_removed_per_ha = log(calories_removed_per_ha + 1)) %>%
  mutate(analysis = "captures") %>%
  select(analysis, subanalysis, bird_group, year, patch, year_patch, control_treatment, exp_phase, net_hours, starts_with("num_birds"), starts_with("num_recaps"), everything())
```

**Import functions**
```{r step1a}
source("code/helper_functions/Modeling_helper_functions.R")
source("code/helper_functions/Plotting_helper_functions.R")
source("code/helper_functions/Extract_data_from_safely_and_quietly_lists.R")
source("code/helper_functions/Calculate_basic_summary_stats.R")
```

**Explore recap data: what is average recapture rate?**
```{r}
#What is average recap rate per site/year?
recap_sum01 <- recapture_data %>%
  group_by(bird_group) %>%
  calculate_basic_summary_stats(variable = recap_rate)

recap_sum01

#Summary in a slightly different way: out of all birds captured, across sites/years, what percentage were recaptured?
recap_sum02 <- recapture_data %>%
  group_by(bird_group) %>%
  summarise(total_birds_pre = sum(num_birds_pre),
            total_recaps_post = sum(num_recaps_post)) %>%
  ungroup() %>%
  mutate(overall_recap_rate = total_recaps_post/total_birds_pre)

recap_sum02
```

## Step 2: Create datasets for each analysis 

**Get organized**
```{r create_table_to_hold_results}
#Create tables that will be filled in with models and model results
analysis = c("captures")
subanalysis = c("captures", "recaptures")
bird_group = c("all_spp", "greh_visa")
model_type = c("categorical", "quantitative")
model_name = c("control/treatment * pre/post", "calories removed/ha * pre/post")
treatment_variable = c("control_treatment", "log_calories_removed_per_ha")
model_types_names = data.frame(model_type = model_type, model_name = model_name, treatment_variable = treatment_variable)

base_table <- crossing(analysis, subanalysis, bird_group, model_type) %>% 
  left_join(model_types_names) %>%
  mutate(yvar = ifelse(subanalysis == "captures", "num_birds", "recap_rate")) %>%
  arrange(analysis, subanalysis, model_type, bird_group) %>%
  mutate(model_number = 1:length(yvar)) %>%
  mutate(title = paste(analysis, subanalysis, bird_group, sep = "_")) %>%
  mutate(subtitle = yvar) %>%
  select(model_number, analysis, yvar, subanalysis, everything())
```

**Filter master dataset to relevant sub-dataset & scale continuous predictors**
```{r}
subset_data <- function(dataset, analysis, subanalysis, bird_group){
  
  dataset <- dataset %>%
    filter(analysis == {{ analysis }}) %>%
    filter(subanalysis == {{ subanalysis}}) %>%
    filter(bird_group == {{ bird_group }}) %>%
    mutate(across(c(log_calories_removed_per_ha, net_hours), ~c(scale(.))))
      
  return(dataset)
  
}

#Create datasets (will add models in later step)
data <- base_table %>%
    mutate(data = pmap(list(analysis, subanalysis, bird_group), ~subset_data(dataset = capture_data_for_analysis, analysis = ..1, subanalysis = ..2, bird_group = ..3)))
```

## Step 3: Initial model fitting

For count data, there multiple possible distributions. I need to choose between Poisson and negative binomial (nbinom1 and nbinom2) and also see if there is support for zero-inflation or not. Will check assumptions for all models again later on.

**Captures**
```{r, include = FALSE, eval = FALSE}
#Filter by hand so can have unscaled value of net-hours for offset
fit_data01 <- capture_data_for_analysis %>%
  filter(analysis == "captures" & subanalysis == "captures" & bird_group == "all_spp")

#Model with net-hours as an offset - gives diagonal lines in residual plot
m1_offset <- glmmTMB::glmmTMB(num_birds ~ control_treatment * exp_phase + offset(log(net_hours)) + (1|patch/year_patch), data = fit_data01, na.action = na.omit, family = "poisson", ziformula = ~0)

simulateResiduals(m1_offset) %>% plot()

#Model with net-hours as a covariate - LOOKS MUCH BETTER
m1_covariate <- glmmTMB::glmmTMB(num_birds ~ control_treatment * exp_phase + net_hours + (1|patch/year_patch), data = fit_data01, na.action = na.omit, family = "poisson", ziformula = ~0)

simulateResiduals(m1_covariate) %>% plot()

#Candidate models with covariate
m1 <- glmmTMB(num_birds ~ control_treatment * exp_phase + net_hours + (1|patch/year_patch), data = fit_data01, na.action = na.omit, family = "poisson", ziformula = ~0)

m2 <- glmmTMB(num_birds ~ control_treatment * exp_phase + net_hours + (1|patch/year_patch), data = fit_data01, na.action = na.omit, family = "poisson", ziformula = ~1)

m3 <- glmmTMB(num_birds ~ control_treatment * exp_phase + net_hours + (1|patch/year_patch), data = fit_data01, na.action = na.omit, family = "nbinom1", ziformula = ~0, control = glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))

m4 <- glmmTMB(num_birds ~ control_treatment * exp_phase + net_hours + (1|patch/year_patch), data = fit_data01, na.action = na.omit, family = "nbinom1", ziformula = ~1, control = glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))

m5 <- glmmTMB(num_birds ~ control_treatment * exp_phase + net_hours + (1|patch/year_patch), data = fit_data01, na.action = na.omit, family = "nbinom2", ziformula = ~0, control = glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))

m6 <- glmmTMB(num_birds ~ control_treatment * exp_phase + net_hours + (1|patch/year_patch), data = fit_data01, na.action = na.omit, family = "nbinom2", ziformula = ~1, control = glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))

#Combine models
model_fitting01 <- tibble(model_name = c("m1", "m2", "m3", "m4", "m5", "m6"), model = list(m1, m2, m3, m4, m5, m6)) %>%
  mutate(dharma_object = map(model, ~simulateResiduals(fittedModel = ., n = 1000, plot = FALSE, re.form = ~0))) %>%
  mutate(dharma_plot = pmap(list(dharma_object, model_name), ~make_dharma_plot(dharma_object = ..1, plot_title = ..2,  plot_type = "basic")),
         dharma_zeroinfl_plot = pmap(list(dharma_object, model_name), ~make_dharma_plot(dharma_object = ..1, plot_title = ..2,  plot_type = "zeroinflation")),
         dharma_overdisp_plot = pmap(list(dharma_object, model_name), ~make_dharma_plot(dharma_object = ..1, plot_title = ..2,  plot_type = "overdispersion"))) %>%
  mutate(AICc = map(model, MuMIn::AICc))

#Which model is best according to AIC?
model_fitting01 %>%
  select(model_name, AICc) %>%
  unnest(AICc) %>%
  arrange(AICc)

#Check to make sure assumptions look OK
model_fitting01$dharma_plot[[1]]
model_fitting01$dharma_overdisp_plot[[1]]
model_fitting01$dharma_zeroinfl_plot[[1]]
```

**Recaptures**
```{r, include = FALSE, eval = FALSE}
fit_data02 <- data %>%
  filter(analysis == "captures" & subanalysis == "recaptures" & bird_group == "all_spp" & model_type == "categorical") %>%
  pull(data) %>%
  as.data.frame()

m1 <- glmmTMB::glmmTMB(recap_rate ~ control_treatment + (1|patch), data = fit_data02, na.action = na.omit, family = "binomial", weights = num_birds_pre, ziformula = ~0)

m2 <- glmmTMB::glmmTMB(recap_rate ~ control_treatment + (1|patch), data = fit_data02, na.action = na.omit, family = "binomial", weights = num_birds_pre, ziformula = ~1)

m3 <- glmmTMB::glmmTMB(recap_rate ~ control_treatment + (1|patch), data = fit_data02, na.action = na.omit, family = "betabinomial", weights = num_birds_pre, ziformula = ~0, control = glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))

m4 <- glmmTMB::glmmTMB(recap_rate ~ control_treatment + (1|patch), data = fit_data02, na.action = na.omit, family = "betabinomial", weights = num_birds_pre, ziformula = ~1, control = glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS")))

#Combine models
model_fitting02 <- tibble(model_name = c("m1", "m2", "m3", "m4"), model = list(m1, m2, m3, m4)) %>%
  mutate(dharma_object = map(model, ~simulateResiduals(fittedModel = ., n = 1000, plot = FALSE, re.form = ~0))) %>%
  mutate(dharma_plot = pmap(list(dharma_object, model_name), ~make_dharma_plot(dharma_object = ..1, plot_title = ..2,  plot_type = "basic")),
         dharma_zeroinfl_plot = pmap(list(dharma_object, model_name), ~make_dharma_plot(dharma_object = ..1, plot_title = ..2,  plot_type = "zeroinflation")),
         dharma_overdisp_plot = pmap(list(dharma_object, model_name), ~make_dharma_plot(dharma_object = ..1, plot_title = ..2,  plot_type = "overdispersion"))) %>%
  mutate(AICc = map(model, MuMIn::AICc))

#Which model is best according to AIC?
model_fitting02 %>%
  select(model_name, AICc) %>%
  unnest(AICc) %>%
  arrange(AICc)

#Check to make sure assumptions look OK
model_fitting02$dharma_plot[[1]]
model_fitting02$dharma_overdisp_plot[[1]]
model_fitting02$dharma_zeroinfl_plot[[1]]
```

## Step 4: Fit models
```{r}
#Function to make model for given analysis
#Alternative optimizer (default is nlminb)
#control = glmmTMBControl(optimizer=optim, optArgs=list(method="BFGS"))
create_model <- function(dataset, analysis, subanalysis, treatment_variable){

  #Make models for each analysis
  if(subanalysis == "captures"){
    
      model <- glmmTMB(as.formula(paste0("num_birds ~ ", treatment_variable, " * exp_phase + net_hours + (1|patch/year_patch)")), data = dataset, na.action = na.omit, family = "poisson", ziformula = ~0)
      
    }
  
  if(subanalysis == "recaptures"){
    
    #Recap rate = # recaps post/# birds pre
    model <- glmmTMB(as.formula(paste0("recap_rate ~ ", treatment_variable, " + (1|patch)")), data = dataset, na.action = na.omit, family = "binomial", weights = num_birds_pre, ziformula = ~0)
    
  }
   
  return(model)
  
}


#Create models
models <- data %>%
   mutate(model_quietly = pmap(list(data, analysis, subanalysis, treatment_variable), quietly(function(a, b, c, d){model <- create_model(dataset = a, analysis = b, subanalysis = c, treatment_variable = d)})),
          model = map(model_quietly, get_result),
          warning = map(model_quietly, get_warning), 
          convergence = map(model, check_convergence)) %>%
  mutate(xvar_table = map(model, ~data.frame(xvar = all.vars(terms(.))[-1])))

#Make sure there weren't any problems + check to make sure table of predictor variables is correct
models$warning
models$convergence
models$xvar_table
```

## Step 5: Check assumptions
```{r, fig.show = 'hide', results = 'hide', eval = FALSE}
assumption_checks <- models %>%
  mutate(re_plot = pmap(list(model, title, subtitle), ~check_re(model = ..1, plot_title = ..2, plot_subtitle = ..3))) %>%
  mutate(dharma_object = map(model, ~simulateResiduals(fittedModel = ., n = 1000, plot = FALSE, re.form = ~0))) %>%
  mutate(dharma_plot_safely = pmap(list(dharma_object, title, subtitle),
                                   safely(function(a, b, c){make_dharma_plot(dharma_object = a, plot_title = b, plot_subtitle = c, plot_type = "basic")})),
         dharma_plot = map(dharma_plot_safely, get_result),
         dharma_plot_error = map(dharma_plot_safely, get_error)) %>%
  mutate(dharma_xvar_plot_safely = pmap(list(xvar_table, data, dharma_object, title, subtitle),
                                        safely(function(a, b, c, d, e){make_dharma_xvar_plot(predictor_table = a, dataset = b, dharma_object = c, plot_title = d, plot_subtitle = e)})),
         dharma_xvar_plot = map(dharma_xvar_plot_safely, get_result),
         dharma_xvar_plot_error = map(dharma_xvar_plot_safely, get_error)) %>%
  mutate(dharma_zeroinfl_plot = pmap(list(dharma_object, title, subtitle), ~make_dharma_plot(dharma_object = ..1, plot_title = ..2, plot_subtitle = ..3, plot_type = "zeroinflation")),
         dharma_overdisp_plot = pmap(list(dharma_object, title, subtitle),  ~make_dharma_plot(dharma_object = ..1, plot_title = ..2, plot_subtitle = ..3, plot_type = "overdispersion"))) %>%
  mutate(plotname1 = paste("re_diagnostics_", model_number, ".png", sep = "")) %>%
  mutate(plotname2 = paste("dharma_overall_diagnostics_", model_number, ".png", sep = "")) %>%
  mutate(plotname3 = paste("dharma_xvar_diagnostics_", model_number, ".png", sep = "")) %>%
  mutate(plotname4 = paste("dharma_zeroinfl_diagnostics_", model_number, ".png", sep = "")) %>%
  mutate(plotname5 = paste("dharma_overdisp_diagnostics_", model_number, ".png", sep = ""))


#Export diagnostic plots because they load very slowly in RStudio
path_name <- c("results/statistical_analysis/assumption_checks/captures")
walk2(assumption_checks$plotname1, assumption_checks$re_plot, ~ggsave(filename = .x, plot = .y, path = path_name, height = 11.5, width = 15, units = "in", bg = "white"))
walk2(assumption_checks$plotname2, assumption_checks$dharma_plot, ~ggsave(filename = .x, plot = .y, path = path_name, height = 11.5, width = 15, units = "in"))
walk2(assumption_checks$plotname3, assumption_checks$dharma_xvar_plot, ~ggsave(filename = .x, plot = .y, path = path_name, height = 11.5, width = 15, units = "in"))
walk2(assumption_checks$plotname4, assumption_checks$dharma_zeroinfl_plot, ~ggsave(filename = .x, plot = .y, path = path_name, height = 11.5, width = 15, units = "in"))
walk2(assumption_checks$plotname5, assumption_checks$dharma_overdisp_plot, ~ggsave(filename = .x, plot = .y, path = path_name, height = 11.5, width = 15, units = "in"))

#Check for highly influential replicates
#Make plots of DFBETAS and Cook's distance
influence_checks <- models %>%
  mutate(influence_plot = pmap(list(model, data, title, subtitle), ~make_influence_plot(model = ..1, dataset = ..2, plot_title = ..3, plot_subtitle = ..4, group_id = "year_patch"))) %>%
  mutate(plotname6 = paste("influence_diagnostics_", model_number, ".png", sep = ""))

#Export plots
walk2(influence_checks$plotname6, influence_checks$influence_plot, ~ggsave(filename = .x, plot = .y, path = path_name, height = 11.5, width = 15, units = "in", bg = "white"))
```

## Step 6: Create results for export
```{r}
#Will also add information about sample size: total # of observations (rows), number of levels per random effect, and the number of replicates (split into 'control' vs. 'treatment')
results <- models %>%
  mutate(summary = map(model, summary),
         summary_tidy = map(model, broom.mixed::tidy),
         confint_wald = map(model, ~calculate_ci(., method_name = "wald"))) %>%
  mutate(num_obs = map(model, get_number_obs),
         num_levels = map(model, get_number_re_levels),
         num_reps = map(data, ~get_sample_size(data = ., vars = c("year", "patch", "control_treatment"), grouping_var = "control_treatment")))
```

## Step 7: Export results as rds file
```{r}
saveRDS(results, "results/statistical_analysis/rds_files/Capture_data_results.rds")
```

*WILL EXTRACT RESULTS, CALCULATE CONTRASTS, MAKE PLOTS, ETC. FROM RDS FILES IN ONE MASTER SCRIPT*